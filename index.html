<!DOCTYPE html>
<html>
	<head>
		<meta charset="UTF-8">
		<link type="text/css" rel="stylesheet" href="indexcss.css" />

		<title>CS 111 Winter 2016 - Lecture 9</title>
	</head>
	<body>
		<h1>CS 111 Winter 2016 - Lecture 9: Synchronization primitives; deadlock</h1>
		<h2>Daniel Lau and Albert Liu</h2>
		
	
		<h3>Lecture Topics:</h3>
		<ol>
			<li><u><a href="#theory-and-policy-issues">Theory and Policy Issues</a></u></li>
			<li><u><a href="#example-bank-account-transfers">Example: Bank Account Transfers</a></u></li>
			<li><u><a href="#example-auditing-the-bank">Example: Auditing the Bank</a></u></li>
			<li><u><a href="#mechanisms">Mechanisms</a></u></li>
			<li><u><a href="#implementing-lock-and-unlock">Implementing Lock and Unlock</a></u></li>
			<li><u><a href="#spin-locks">Spin Locks</a></u></li>
		</ol>

		<h3 id="theory-and-policy-issues">Theory and Policy Issues</h3>
		<div>
			<h4>A brief review of the last lecture - Goldilocks Principle</h4>
			<p>The Goldilocks Principle says that critical sections should not be</p>
			<ul>
				<li>too small, or many races could still occur</li>
				<li>too large, because then there is not much parallelism and your code is terrible</li>
			</ul>
			<p>In these critical sections, there are shared data or resources that should only be accessed or modified by one user at a time. To lock critical sections, we use code like so:</p>
	<pre><code>
	lock(obj);
	perform delicate actions on obj
	unlock(obj);
	</code></pre>
		
		<h4 id="example-bank-account-transfers">Example: Bank Account Transfers</h4>
		<p>Let us consider an example where we are transferring money from an account A to account B. To ensure correctness of transfer, we do not want anyone performing any operations on the accounts while we are transferring the money. We can use locks to transfer money like so:</p>
	<pre><code>
	lock(account A);
	remove money out of account A;
	unlock(account A);

	lock(account B);
	add money into account B;
	unlock(account B);
	</code></pre>
		<p> However, notice that if a bank auditor takes an audit between unlock(account A) and lock(account B), the total balance in the bank won't add up. This means our critical section is <b>too</b> small! We can solve this issue by moving our locks and unlocks like so, locking both accounts before any transfers are made:</p>
	<pre><code>
	lock(account A);
	lock(account B);
	remove money out of account A;
	add money into account B;
	unlock(account B);
	unlock(account A);
	</code></pre>
		<p> However, this solution is still <i>non-optimal</i> because we use multiple locks. If someone already has a lock on one of the resources, in this case account A or account B, we end up waiting for an indefinite time, with a potential for deadlocking if the critical section is too large.</p>
		
		<h4 id="example-auditing-the-bank">Example: Auditing the Bank</h4>
		<p>As demonstrated previously, taking an audit can result in problems if our critical sections are too small and we audit in the middle of a transfer. Considering our proposed solution, if we decide to audit the entire bank, we will need to put a lock on all accounts. Clearly, this solution is not perfect as no transactions can be made during that time. It is also just as difficult to find an optimal time to perform the audit. If any transactions are being made while we request an audit, we need to wait for those transactions to complete and release the lock on the accounts. We can alternatively forcefully boot everyone off of the system, but this will result in unhappy users. </p>
		<p>Putting the problem of finding an optimal time aside, one solution to avoid locking all accounts involves assuming that our file system will be able to take a snapshot. We will then perform the audit on the snapshot, guaranteeing that no users will request locks on anything in the snapshot (as it does hold any actual accounts, only the status of them at a specific time). Implementing file system snapshots is fairly advanced to implement, which will be a problem for another day.</p>
		
		</div>

		<h3 id="mechanisms">Mechanisms</h3>
		<p>So how do we solve the locking problem? This requires us to consider implementations.</p>
		<div>
		<h4>Implementing on a uniprocessor</h4>
			<p>Assumptions</p>
			<ul>
			<li>We have one processor</li>
			<li>No other process is running</li>
			</ul>
			<p>Solutions</p>
			<ul>
			<li>Disable interrupts (especially the clock interrupt) during critical sections</li>
			<li>Use cooperative multitasking so no context switching is forced during a critical section</li>
			</ul>
		<h4>Implementing on a multiprocessor</h4>
		<p>Let us assume a sample program involving pipes that we are implementing on our own</p>
		<p><b>insert picture of the pipe here</b></p>
		<p>We define a simple pipe with the following code:</p>
	<pre><code>
	struct pipe {
		char buf[1024];
		unsigned r, w;
	}
	</pre></code>
		<p>To keep things simple, we will implement read and write system calls for 1 byte. Our example implementation of read and write is as follows:</p>
	<pre><code>
	bool write_pipe(struct pipe *p, char c){
		lock(&p->lock); //add in after locks
		if(p->w - p->r == 1024)
			return false;
		p->buf[p->w++%1024] = c;
		unlock(&p->lock); //add in after locks
		return true;
	}
	int read_pipe(struct pipe *p){
		if(p->w == p->r)
			return CHAR_MIN-1;
		return p->buf[p->r++%1024];
	}
	</pre></code>
		
		<h4 id="implementing-lock-and-unlock">Developing a Synchronization Primitive: Implementing Lock and Unlock</h4>
		<p>We can implement lock and unlock as either:</p>
		<ul>
		<li>As system calls (easily doable, but often times not fast enough) </li>
		<li>As plain machine instructions (difficult, but very fast) </li>
	</ul>

	<pre><code>
	/*precondition: lock not held by the caller
	postcondition: lock held by the caller*/
	typedef char lock_t;
	void lock(lock_t *l) {
		while(*l)
			continue;
		*l = 1;
	}

	/*precondition: lock is held by the caller
	postcondition: lock no longer held by the caller*/
	void unlock(lock_t *l) {
		*l = 0;
	}
	</code></pre>

	<p>However, notice that there's a race condition present in the lock function. So lock needs a lock which needs a lock... which means we must turn to the hardware level </p>
	<p>So how does hardware access actually work? Cache lines grab you 32 bytes (for example) at a time. So all loads and stores to RAM are 32 bytes at once </p>
	<p><b>Demonstrate the cache coherence problem here</b></p>
	<p>To solve the cache coherence problem, we can</p>
	<ul>
		<li>Disable cache (bad solution, results in a heavy slowdown</li>
		<li>Snoop the bus and invalidate cache (not optimal solution either, can slow down the program)</li>
		<li>Use an instruction that can make the lock function atomic</li>
	</ul>

	<h4 id="spin-locks">Spin Locks</h4>
	<p>Spin locks are a particular type of lock in which a thread trying to acquire a resource will simply wait in a loop and "spin", constantly checking if the lock is available. Because spin locks employ this sort of busy waiting, they consume valuable CPU time. However, they are particularly easy to implement and are additionally lightweight. In this section, we will formulate how to implement spin locks, adapting our naive implementation of lock and unlock above. We will see that the functionality of spin locks are very similar to the basic lock implementation above. However, spin locks have atomicity and prevent race conditions.</p>
	<p>The spin locks should not be: </p>
	<ul>
	<li>too large (e.g. don't use typedef __int 128 lock_t as that requires two 64-bit instructions to process, making it non-atomic on the hardware level)</li>
	<li>too small (e.g. don't use unsigned char lock:1; bitfields, as that requires the ALU to shift your word to isolate the bit field and compute with it)</li>
	</ul>
	<p>On x86 and x86-64 computers, int is acceptable as long as it is aligned</p>
	<p>With choosing spin locks, we also need extra machine instructions for an atomic access to int, such as the additional instruction:</p>
	<pre><code>
	lock incl (mem_addr)
	</pre></code>
	<p>By prepending lock to the instruction, the CPU sends out a warning over the bus enabling us to lock atomically.</p>

	<p>For implementing a spin lock, we use the machine instruction xchgl, which exchanges two values atomically. An example of its operation is shown below in C, but is atomic in hardware:</p>
	<pre><code>
	//store val into *p and return original value held by p
	int xchgl(int *p, int val){
		int old = *p;
		*p = val;
		return old;
	}
	</pre></code>

	Upon trying to acquire a lock, we can use the code below, where we atomically check for whether the lock is available. Since the lock is not available unless the value stored in l is 1, we will "spin" inside the while loop until the lock is available, where the value stored in l is 0.

	<pre><code>
	void lock(int *l){
		while(xchgl(l, 1))
			continue;
	}
	</pre></code>

	<pre><b>Explain the shit below.</b></pre>

	<pre><code><!-- 
	lock(&l);
	x = f(x);
	unlock(&l);

	BAD CODE BELOW
	int old = x;
	int new = f(x);
	while(xchgl(&x, new) != old)
		continue;
	BAD CODE ABOVE -->
	//compare and swap instruction
	//if *p == old, store new into p
	bool cas(int *p, int old, int new){
		if(*p == old){
			*p = new;
			return true;
		}
		else
			return false;
	}

	do {
		int old = x;
		int new = f(x);
	} while (cas(&x, old, f(x));
	</pre></code>

	<p>Key note: machine instructions enable us to make bigger building blocks in software. This is demonstrated by now correctly having the data buffer in our pipe proected by the lock_t data variable in our pipe struct</p>

	<pre><code>
	So we've successfully created three different machine instructions:
	asm("lock incl m");
	asm("xchgl r, m");
	asm("cas r, m")
	</pre></code>

	<h4>Further problems with our pipe</h4>
	<p>We cannot have a global lock, because otherwise if we have N threads accessing any pipe, at worst case we will have N-1 threads spinning while the pipe is being written or read from.</p>
	<p>Coarse-Grained Locking, e.g. global lock</p>
	<ul>
	<li><b>Good:</b> Simple to implement and use </li>
	<li><b>Bad:</b> As shown previously, can be a performance bottleneck
	</ul>
	<p>Fine-Grained Locking</p>
	<ul>
	<li><b>Good:</b> Fewer bottlenecks </li>
	<li><b>Bad:</b> Complex to implement </li>
	</ul>

	<p>We also do not want to use separate read and write locks, because it's not standard and easily adaptable. Solution if many readers and few writers?</p>
	<pre><code>
	reader:
	while((c = read_pipe(&p)) == CHAR_MIN-1)
		yield(); //so as not to continue eating CPU time while attempting to read
	do_work(); //reach this when successfully read
	//this involves cooperative multitasking!
	</pre></code>

	<h3>Further problems for the future</h3>
	<p>What if we have a small number of writers and a large number of readers waiting on a pipe (useless readers)? We need our scheduler to have some way of skipping over all those readers... Tune in next time to find out how!</p>

</div>
	</body>
</html>